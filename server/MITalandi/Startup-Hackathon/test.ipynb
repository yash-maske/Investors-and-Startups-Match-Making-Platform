{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "cbBtErCG1nti",
    "ExecuteTime": {
     "end_time": "2025-04-10T14:10:11.962085Z",
     "start_time": "2025-04-10T14:10:11.949226Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "stop_words = nlp.Defaults.stop_words\n",
    "ps = PorterStemmer()"
   ],
   "metadata": {
    "id": "slGFNd7M1sc0",
    "ExecuteTime": {
     "end_time": "2025-04-10T14:10:14.720701Z",
     "start_time": "2025-04-10T14:10:14.443649Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "id": "tpkYLle7b6DD",
    "ExecuteTime": {
     "end_time": "2025-04-10T14:10:16.512512Z",
     "start_time": "2025-04-10T14:10:16.508623Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": "df = pd.read_csv(r'startups.csv')",
   "metadata": {
    "id": "Qro3rz181s9X",
    "ExecuteTime": {
     "end_time": "2025-04-10T14:10:53.468378Z",
     "start_time": "2025-04-10T14:10:53.447507Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "df1 = df.copy()"
   ],
   "metadata": {
    "id": "gTAzAF_11vNP",
    "ExecuteTime": {
     "end_time": "2025-04-10T14:10:55.529032Z",
     "start_time": "2025-04-10T14:10:55.526143Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": "df_f = df1[['Company/Brand/Brand','Sector','What it does','Amount']]",
   "metadata": {
    "id": "RwQLAVzM1xC7",
    "ExecuteTime": {
     "end_time": "2025-04-10T14:11:48.480833Z",
     "start_time": "2025-04-10T14:11:48.465609Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "def stem(text):\n",
    "    y=[]\n",
    "    for i in text.split():\n",
    "        y.append(ps.stem(i))\n",
    "    return \" \".join(y)"
   ],
   "metadata": {
    "id": "mordXSIQ1zd7",
    "ExecuteTime": {
     "end_time": "2025-04-10T14:11:50.140981Z",
     "start_time": "2025-04-10T14:11:50.138323Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "def preprocessing(df,column):\n",
    "    df[column] = df[column].apply(lambda x:x.split())\n",
    "    df[column] = df[column].apply(lambda x:[i.replace(\" \",\"\") for i in x])\n",
    "    df[column] = df[column].apply(lambda x:\" \".join(x))\n",
    "    df[column] = df[column].apply(stem)\n",
    "    df[column] = df[column].apply(lambda x: nlp(x.lower()))\n",
    "    df[column] = [' '.join([token.lemma_ for token in doc]) for doc in df[column]]\n",
    "    df[column] = [' '.join([word for word in doc.split() if word not in stop_words]) for doc in df[column]]\n",
    "    df[column].replace(\"[^a-zA-Z]\",\" \",regex=True, inplace=True)"
   ],
   "metadata": {
    "id": "OExEsG7r119t",
    "ExecuteTime": {
     "end_time": "2025-04-10T14:11:52.413315Z",
     "start_time": "2025-04-10T14:11:52.408241Z"
    }
   },
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "def desc_similarity(df,column1,column2):\n",
    "  d = {}\n",
    "  d['Company/Brand/Brand'] = ''\n",
    "  d['Sector'] = \"Web Development\"\n",
    "  d['What it does'] = \"SAAS methodology\"\n",
    "  d['Amount'] = 500000\n",
    "\n",
    "  d = pd.DataFrame([d])\n",
    "  df = pd.concat([df_f, d], axis=0, ignore_index=True)\n",
    "\n",
    "  preprocessing(df_f,column1)\n",
    "\n",
    "  df1 = df_f[['Company/Brand',column1]]\n",
    "  df2 = df_f[['Company/Brand',column2]]\n",
    "\n",
    "  tfidf = TfidfVectorizer(stop_words = \"english\")\n",
    "  tfidf_matrix = tfidf.fit_transform(df1[column1])\n",
    "  tfidf_matrix_df=pd.DataFrame.sparse.from_spmatrix(tfidf_matrix)\n",
    "  df_final=tfidf_matrix_df\n",
    "\n",
    "  x = df_final.iloc[[-1],:] \n",
    "  y = df_final.iloc[:-2,:]\n",
    "\n",
    "  # Calculate the similarity matrix\n",
    "  sim_matrix=cosine_similarity(x,y)\n",
    "  df_sim_matrix = pd.DataFrame(sim_matrix)\n",
    "  sim_scores = list(enumerate(sim_matrix[0]))\n",
    "  sim_scores = sorted(sim_scores, key=lambda x:x[1], reverse = True)\n",
    "  s_idx  =  [i[0] for i in sim_scores]\n",
    "  s_scores =  [i[1] for i in sim_scores]\n",
    "\n",
    "  df_similar = pd.DataFrame(columns=[\"Company/Brand\", \"Score\"])\n",
    "  df_similar[\"Company/Brand\"] = df1.loc[s_idx, \"Company/Brand\"]\n",
    "  df_similar[\"Score\"] = s_scores\n",
    "  df_similar=df_similar.loc[(df_similar['Company/Brand'] !='')]\n",
    "  df_similar=df_similar.drop_duplicates(subset='Company/Brand', keep=\"first\")\n",
    "\n",
    "  \n",
    "  df_similar_N = df_similar.iloc[0:4+1,:]\n",
    "  df_similar_N = pd.merge(df_similar_N, df2, left_on='Company/Brand', right_on='Company/Brand')\n",
    "  df_similar_N = df_similar_N[df_similar_N['Amount']<=df_similar_N['Amount'].iloc[-1]]\n",
    "  df_similar_N.reset_index(inplace = True)\n",
    "  ca = df_similar_N['Company/Brand'].values.tolist() \n",
    "    \n",
    "  # Return the similarity matrix\n",
    "  return ca"
   ],
   "metadata": {
    "id": "-_GbK_e712Yn",
    "ExecuteTime": {
     "end_time": "2025-04-10T14:13:03.471027Z",
     "start_time": "2025-04-10T14:13:03.464217Z"
    }
   },
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "a = desc_similarity(df_f,\"What it does\",\"Amount\")\n",
    "print(a)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oxYgR2Sa4WI-",
    "outputId": "4f5166b3-754f-4291-ca20-727cf8e56ac6",
    "ExecuteTime": {
     "end_time": "2025-04-10T14:13:12.152182Z",
     "start_time": "2025-04-10T14:13:07.446957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Elixia Tech Solutions', 'Nexprt']\n"
     ]
    }
   ],
   "execution_count": 16
  }
 ]
}
